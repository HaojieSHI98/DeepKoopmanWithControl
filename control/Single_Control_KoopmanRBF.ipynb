{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import argparse\n",
    "from collections import OrderedDict\n",
    "from copy import copy\n",
    "import scipy\n",
    "import scipy.linalg\n",
    "import sys\n",
    "sys.path.append(\"../utility\")\n",
    "sys.path.append(\"../train\")\n",
    "from Utility import DerivativeLiftFunc, data_collecter,RBFLiftFunc\n",
    "import lqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Methods = [\"KoopmanDerivative\",\"KoopmanRBF\",\\\n",
    "            \"KNonlinear\",\"KNonlinearRNN\",\"KoopmanU\",\\\n",
    "            \"KoopmanNonlinearA\",\"KoopmanNonlinear\",\\\n",
    "                ]\n",
    "method_index = 1\n",
    "# suffix = \"CartPole1_26\"\n",
    "# env_name = \"CartPole-v1\"\n",
    "# suffix = \"Pendulum1_26\"\n",
    "# env_name = \"Pendulum-v1\"\n",
    "# suffix = \"DampingPendulum1_26\"\n",
    "# env_name = \"DampingPendulum\"\n",
    "suffix = \"MountainCarContinuous1_26\"\n",
    "env_name = \"MountainCarContinuous-v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = np.load(\"Prediction_Results/\"+\"Kd_\"+env_name+\"_KoopmanRBF\"+\".npz\")\n",
    "Kd = Data[\"Kd\"]\n",
    "center = Data[\"Center\"]\n",
    "Data_collecter = data_collecter(env_name)\n",
    "Nstate = Data_collecter.Nstates\n",
    "udim = Data_collecter.udim\n",
    "Nrbf = 50\n",
    "LiftFunc = RBFLiftFunc(env_name,Nstate,udim,Nrbf,Data_collecter.observation_space,center=center)\n",
    "NKoopman = LiftFunc.NKoopman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Prepare_LQR(env_name):\n",
    "    x_ref = np.zeros(Nstate)\n",
    "    if env_name.startswith(\"CartPole\"):\n",
    "        Q = np.zeros((NKoopman,NKoopman))\n",
    "        Q[1,1] = 0.01\n",
    "        Q[2,2] = 5.0\n",
    "        Q[3,3] = 0.01\n",
    "        R = 0.001*np.eye(1)\n",
    "        reset_state=  [0.0,0.0,-1.0,0.1]\n",
    "    elif env_name.startswith(\"Pendulum\"):\n",
    "        Q = np.zeros((NKoopman,NKoopman))\n",
    "        Q[0,0] = 5.0\n",
    "        Q[1,1] = 0.01\n",
    "        R = 0.01*np.eye(1)\n",
    "        reset_state = [-3.0,6.0]\n",
    "    elif env_name.startswith(\"DampingPendulum\"):\n",
    "        Q = np.zeros((NKoopman,NKoopman))\n",
    "        Q[0,0] = 5.0\n",
    "        Q[1,1] = 0.01\n",
    "        R = 100*np.eye(1)\n",
    "        reset_state = [-3.0,2.0]   \n",
    "    elif env_name.startswith(\"MountainCarContinuous\"):\n",
    "        Q = np.zeros((NKoopman,NKoopman))\n",
    "        Q[0,0] = 5.0\n",
    "        Q[1,1] = 0.01\n",
    "        R = 0.01*np.eye(1)\n",
    "        reset_state = [-0.3,0.1]  \n",
    "        x_ref[0] = 0.45\n",
    "    Q = np.matrix(Q)\n",
    "    R = np.matrix(R)\n",
    "    return Q,R,reset_state,x_ref\n",
    "    \n",
    "def criterion(env_name,observations):\n",
    "    if env_name.startswith(\"CartPole\"):\n",
    "        err = np.mean(abs(observations[2:,195:]))\n",
    "    elif env_name.startswith(\"Pendulum\"):\n",
    "        err = np.mean(abs(observations[:,195:]))\n",
    "    elif env_name.startswith(\"DampingPendulum\"):\n",
    "        err = np.mean(abs(observations[:,195:]))\n",
    "    elif env_name.startswith(\"MountainCarContinuous\"):\n",
    "        err = np.mean(abs(observations[0,195:]-0.45))+np.mean(abs(observations[1,195:]))\n",
    "    return err\n",
    "\n",
    "def Cost(observations,u_list,Q,R,x_ref):\n",
    "    steps = observations.shape[1]\n",
    "    loss = 0\n",
    "    for s in range(steps):\n",
    "        if s!=steps-1:\n",
    "            ucost = np.dot(np.dot(u_list[s].T,R),u_list[s])\n",
    "            loss += ucost[0,0]\n",
    "        xcost = np.dot(np.dot((observations[:,s]-x_ref).T,Q),(observations[:,s]-x_ref))\n",
    "        loss += xcost[0,0]\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25156/2013866428.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mKopt\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx_ref_lift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLiftFunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPsi_s\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNKoopman\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mobservation_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mNstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Koopman/gym/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         ), \"Cannot call env.step() before calling reset()\"\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Koopman/gym/gym/envs/classic_control/continuous_mountain_car.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m# force = min(max(action[0], self.min_action), self.max_action)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mvelocity\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.0025\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;31m# if velocity > self.max_speed:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;31m#     velocity = self.max_speed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "Ad = Kd[:NKoopman,:NKoopman]\n",
    "Bd = Kd[:NKoopman,NKoopman:]\n",
    "env = Data_collecter.env\n",
    "env.reset()\n",
    "import lqr\n",
    "import time\n",
    "Ad = np.matrix(Ad)\n",
    "Bd = np.matrix(Bd)\n",
    "Q,R,reset_state,x_ref = Prepare_LQR(env_name)\n",
    "reset_state = [-0.3,0.1]\n",
    "uval = 0.01 \n",
    "Kopt = lqr.lqr_regulator_k(Ad,Bd,Q,uval*R)\n",
    "observation_list = []\n",
    "observation = np.array(env.reset_state(reset_state))\n",
    "x0 = np.matrix(LiftFunc.Psi_s(observation)).reshape(NKoopman,1)\n",
    "x_ref_lift = LiftFunc.Psi_s(x_ref).reshape(NKoopman,1)\n",
    "observation_list.append(x0[:Nstate].reshape(-1,1))\n",
    "# print(Kopt)\n",
    "u_list = []\n",
    "steps = 200\n",
    "# umax = 100\n",
    "for i in range(steps):\n",
    "    u = -Kopt*(x0-x_ref_lift)\n",
    "    observation, reward, done, info = env.step(u[0,0])\n",
    "    x0 = np.matrix(LiftFunc.Psi_s(observation)).reshape(NKoopman,1)\n",
    "    observation_list.append(x0[:Nstate].reshape(-1,1))\n",
    "    u_list.append(u)\n",
    "observations = np.concatenate(observation_list,axis=1)\n",
    "u_list = np.array(u_list).reshape(-1)\n",
    "np.save(\"SingleControlResults/\"+env_name+\"_KoopmanRBF_obs.npy\",observations)\n",
    "Err = criterion(env_name,observations)\n",
    "loss = Cost(observations,u_list,Q[:Nstate,:Nstate],0.0*R,x_ref)\n",
    "print(Err,loss)\n",
    "time_history = np.arange(steps+1)*env.dt\n",
    "for i in range(Nstate):\n",
    "    plt.plot(time_history, observations[i,:].reshape(-1,1), label=\"x{}\".format(i))\n",
    "plt.grid(True)\n",
    "plt.title(\"LQR Regulator\")\n",
    "plt.legend()\n",
    "plt.savefig(\"SingleControlResults/\"+env_name+\"_KoopmanRBF.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4d06311c44a4bca643a5b6bd1fed619513a1bbcc6119049a755b6c84aad7bef"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
